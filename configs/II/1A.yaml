# from simsio import gen_configs
# import numpy as np
# params = {
#     "N": 1000 * 2 ** np.arange(5),
#     "train_frac": np.arange(6, 10) / 10,
# }
# gen_configs("template", params, "II/1A")
===:
  template: |
    n$enum:
      <<<: common
      input: {N: $N, train_frac: $train_frac}
  common:
    samples: 100
    input:
      rescale: 50
      offset: 0
    model:
      layers:
      - tf.keras.layers.Dense(2, activation="relu")
      - tf.keras.layers.Dense(20, activation="relu")
      - tf.keras.layers.Dense(20, activation="relu")
      - tf.keras.layers.Dropout(0.2)
      - tf.keras.layers.Dense(1, activation="sigmoid")
    compile:
      loss: binary_crossentropy
      optimizer: adam
      metrics: [accuracy]
      steps_per_execution: 4
    fit:
      epochs: 500
      batch_size: 50
      verbose: 0
n0:
  <<<: common
  input: {N: 1000, train_frac: 0.6}
n1:
  <<<: common
  input: {N: 1000, train_frac: 0.7}
n2:
  <<<: common
  input: {N: 1000, train_frac: 0.8}
n3:
  <<<: common
  input: {N: 1000, train_frac: 0.9}
n4:
  <<<: common
  input: {N: 2000, train_frac: 0.6}
n5:
  <<<: common
  input: {N: 2000, train_frac: 0.7}
n6:
  <<<: common
  input: {N: 2000, train_frac: 0.8}
n7:
  <<<: common
  input: {N: 2000, train_frac: 0.9}
n8:
  <<<: common
  input: {N: 4000, train_frac: 0.6}
n9:
  <<<: common
  input: {N: 4000, train_frac: 0.7}
n10:
  <<<: common
  input: {N: 4000, train_frac: 0.8}
n11:
  <<<: common
  input: {N: 4000, train_frac: 0.9}
n12:
  <<<: common
  input: {N: 8000, train_frac: 0.6}
n13:
  <<<: common
  input: {N: 8000, train_frac: 0.7}
n14:
  <<<: common
  input: {N: 8000, train_frac: 0.8}
n15:
  <<<: common
  input: {N: 8000, train_frac: 0.9}
n16:
  <<<: common
  input: {N: 16000, train_frac: 0.6}
n17:
  <<<: common
  input: {N: 16000, train_frac: 0.7}
n18:
  <<<: common
  input: {N: 16000, train_frac: 0.8}
n19:
  <<<: common
  input: {N: 16000, train_frac: 0.9}


