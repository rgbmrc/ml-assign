# from simsio import gen_configs
# import numpy as np
# params = {
#     "rescale": np.logspace(-1, 2, 4),
#     "lr": np.logspace(-3.5, -1.5, 5),
# }
# gen_configs("template", params, "II/3A")
===:
  template: |
    n$enum:
      <<<: common
      input: {rescale: $rescale}
      compile: {optimizer: {config: {learning_rate: $lr}}}
  common:
    samples: 100
    input:
      N: 4000
      train_frac: 0.8
      offset: 0
    model:
      layers:
      - tf.keras.layers.Dense(2, activation="elu")
      - tf.keras.layers.Dense(20, activation="elu")
      - tf.keras.layers.Dense(20, activation="elu")
      - tf.keras.layers.Dropout(0.2)
      - tf.keras.layers.Dense(1, activation="sigmoid")
    compile:
      loss: binary_crossentropy
      optimizer:
        class_name: adam
      metrics: [accuracy]
      steps_per_execution: 4
    fit:
      epochs: 500
      batch_size: 50
      verbose: 0
n0:
  <<<: common
  input: {rescale: 0.1}
  compile: {optimizer: {config: {learning_rate: 0.00031622776601683794}}}
n1:
  <<<: common
  input: {rescale: 0.1}
  compile: {optimizer: {config: {learning_rate: 0.001}}}
n2:
  <<<: common
  input: {rescale: 0.1}
  compile: {optimizer: {config: {learning_rate: 0.0031622776601683794}}}
n3:
  <<<: common
  input: {rescale: 0.1}
  compile: {optimizer: {config: {learning_rate: 0.01}}}
n4:
  <<<: common
  input: {rescale: 0.1}
  compile: {optimizer: {config: {learning_rate: 0.03162277660168379}}}
n5:
  <<<: common
  input: {rescale: 1.0}
  compile: {optimizer: {config: {learning_rate: 0.00031622776601683794}}}
n6:
  <<<: common
  input: {rescale: 1.0}
  compile: {optimizer: {config: {learning_rate: 0.001}}}
n7:
  <<<: common
  input: {rescale: 1.0}
  compile: {optimizer: {config: {learning_rate: 0.0031622776601683794}}}
n8:
  <<<: common
  input: {rescale: 1.0}
  compile: {optimizer: {config: {learning_rate: 0.01}}}
n9:
  <<<: common
  input: {rescale: 1.0}
  compile: {optimizer: {config: {learning_rate: 0.03162277660168379}}}
n10:
  <<<: common
  input: {rescale: 10.0}
  compile: {optimizer: {config: {learning_rate: 0.00031622776601683794}}}
n11:
  <<<: common
  input: {rescale: 10.0}
  compile: {optimizer: {config: {learning_rate: 0.001}}}
n12:
  <<<: common
  input: {rescale: 10.0}
  compile: {optimizer: {config: {learning_rate: 0.0031622776601683794}}}
n13:
  <<<: common
  input: {rescale: 10.0}
  compile: {optimizer: {config: {learning_rate: 0.01}}}
n14:
  <<<: common
  input: {rescale: 10.0}
  compile: {optimizer: {config: {learning_rate: 0.03162277660168379}}}
n15:
  <<<: common
  input: {rescale: 100.0}
  compile: {optimizer: {config: {learning_rate: 0.00031622776601683794}}}
n16:
  <<<: common
  input: {rescale: 100.0}
  compile: {optimizer: {config: {learning_rate: 0.001}}}
n17:
  <<<: common
  input: {rescale: 100.0}
  compile: {optimizer: {config: {learning_rate: 0.0031622776601683794}}}
n18:
  <<<: common
  input: {rescale: 100.0}
  compile: {optimizer: {config: {learning_rate: 0.01}}}
n19:
  <<<: common
  input: {rescale: 100.0}
  compile: {optimizer: {config: {learning_rate: 0.03162277660168379}}}


