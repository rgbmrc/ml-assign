# from simsio import gen_configs
# params = {
#     "activation": [
#         "elu",
#         "relu",
#         "sigmoid",
#         "softsign",
#         "tanh",
#     ],
#     "optimizer": [
#         "adam",
#         "adamax",
#         "rmsprop",
#         "sgd",
#     ],
# }
# gen_configs("template", params, "II/2A")
===:
  template: |
    n$enum:
      <<<: common
      compile: {optimizer: $optimizer}
      model: {vars: {activation: $activation}}
  common:
    samples: 100
    input:
      N: 8000
      train_frac: 0.8
      rescale: 50
      offset: 0
    model:
      layers:
      - tf.keras.layers.Dense(2, activation=activation)
      - tf.keras.layers.Dense(20, activation=activation)
      - tf.keras.layers.Dense(20, activation=activation)
      - tf.keras.layers.Dropout(0.2)
      - tf.keras.layers.Dense(1, activation="sigmoid")
    compile:
      loss: binary_crossentropy
      metrics: [accuracy]
      steps_per_execution: 4
    fit:
      epochs: 500
      batch_size: 50
      verbose: 0
n0:
  <<<: common
  compile: {optimizer: adam}
  model: {vars: {activation: elu}}
n1:
  <<<: common
  compile: {optimizer: adamax}
  model: {vars: {activation: elu}}
n2:
  <<<: common
  compile: {optimizer: rmsprop}
  model: {vars: {activation: elu}}
n3:
  <<<: common
  compile: {optimizer: sgd}
  model: {vars: {activation: elu}}
n4:
  <<<: common
  compile: {optimizer: adam}
  model: {vars: {activation: relu}}
n5:
  <<<: common
  compile: {optimizer: adamax}
  model: {vars: {activation: relu}}
n6:
  <<<: common
  compile: {optimizer: rmsprop}
  model: {vars: {activation: relu}}
n7:
  <<<: common
  compile: {optimizer: sgd}
  model: {vars: {activation: relu}}
n8:
  <<<: common
  compile: {optimizer: adam}
  model: {vars: {activation: sigmoid}}
n9:
  <<<: common
  compile: {optimizer: adamax}
  model: {vars: {activation: sigmoid}}
n10:
  <<<: common
  compile: {optimizer: rmsprop}
  model: {vars: {activation: sigmoid}}
n11:
  <<<: common
  compile: {optimizer: sgd}
  model: {vars: {activation: sigmoid}}
n12:
  <<<: common
  compile: {optimizer: adam}
  model: {vars: {activation: softsign}}
n13:
  <<<: common
  compile: {optimizer: adamax}
  model: {vars: {activation: softsign}}
n14:
  <<<: common
  compile: {optimizer: rmsprop}
  model: {vars: {activation: softsign}}
n15:
  <<<: common
  compile: {optimizer: sgd}
  model: {vars: {activation: softsign}}
n16:
  <<<: common
  compile: {optimizer: adam}
  model: {vars: {activation: tanh}}
n17:
  <<<: common
  compile: {optimizer: adamax}
  model: {vars: {activation: tanh}}
n18:
  <<<: common
  compile: {optimizer: rmsprop}
  model: {vars: {activation: tanh}}
n19:
  <<<: common
  compile: {optimizer: sgd}
  model: {vars: {activation: tanh}}


